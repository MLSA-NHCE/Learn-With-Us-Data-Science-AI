{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "#nltk.download(\"punkt\")\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def tokenize(sentence):\n",
    "    return nltk.word_tokenize(sentence)\n",
    "\n",
    "def stem(word):\n",
    "    return stemmer.stem(word.lower())\n",
    "\n",
    "def bag_of_words(tokenize_sentence, all_words):\n",
    "    tokenize_sentence = [stem(w) for w in tokenize_sentence]\n",
    "    bag = np.zeros(len(all_words),dtype = np.float32)\n",
    "    for idx,w in enumerate(all_words):\n",
    "        if w in tokenize_sentence:\n",
    "            bag[idx] = 1.0\n",
    "    return bag\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'s\", 'a', 'accept', 'anyon', 'are', 'bye', 'can', 'card', 'cash', 'credit', 'day', 'deliveri', 'do', 'doe', 'funni', 'get', 'good', 'goodby', 'have', 'hello', 'help', 'hey', 'hi', 'how', 'i', 'is', 'item', 'joke', 'kind', 'know', 'later', 'long', 'lot', 'mastercard', 'me', 'my', 'of', 'onli', 'pay', 'paypal', 'see', 'sell', 'ship', 'someth', 'take', 'tell', 'thank', 'that', 'there', 'what', 'when', 'which', 'with', 'you']\n",
      "['delivery', 'funny', 'goodbye', 'greeting', 'items', 'payments', 'thanks']\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 1.]] [3 3 3 3 3 3 2 2 2 6 6 6 6 4 4 4 5 5 5 5 0 0 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#train.py\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "with open(\"intents.json\",'r') as f:\n",
    "    intents = json.load(f)\n",
    "\n",
    "all_words = []\n",
    "tags = []\n",
    "xy = []\n",
    "\n",
    "for intent in intents['intents']:\n",
    "    tag = intent['tag']\n",
    "    tags.append(tag)\n",
    "    for pattern in intent['patterns']:\n",
    "        w = tokenize(pattern)\n",
    "        all_words.extend(w)\n",
    "        xy.append((w,tag))\n",
    "        \n",
    "ignore_words = ['?','!','.',',']\n",
    "all_words = [stem(w) for w in all_words if w not in ignore_words]\n",
    "all_words = sorted(set(all_words))\n",
    "tags = sorted(set(tags))\n",
    "print(all_words)\n",
    "print(tags)\n",
    "\n",
    "X_train =[]\n",
    "y_train = []\n",
    "\n",
    "for (pattern_sentence,tag) in xy:\n",
    "    bag = bag_of_words(pattern_sentence,all_words)\n",
    "    X_train.append(bag)\n",
    "    label = tags.index(tag)\n",
    "    y_train.append(label)\n",
    "    \n",
    "    \n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "print(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "#model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(300, input_shape = (54,),activation= tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(300, activation= tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(len(tags), activation= tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26 samples\n",
      "Epoch 1/50\n",
      "26/26 [==============================] - 0s 18ms/sample - loss: 1.9518 - accuracy: 0.1538\n",
      "Epoch 2/50\n",
      "26/26 [==============================] - 0s 231us/sample - loss: 1.8622 - accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "26/26 [==============================] - 0s 115us/sample - loss: 1.7788 - accuracy: 0.7692\n",
      "Epoch 4/50\n",
      "26/26 [==============================] - 0s 115us/sample - loss: 1.6999 - accuracy: 0.9231\n",
      "Epoch 5/50\n",
      "26/26 [==============================] - 0s 193us/sample - loss: 1.6245 - accuracy: 0.9231\n",
      "Epoch 6/50\n",
      "26/26 [==============================] - 0s 116us/sample - loss: 1.5508 - accuracy: 0.9231\n",
      "Epoch 7/50\n",
      "26/26 [==============================] - 0s 154us/sample - loss: 1.4775 - accuracy: 0.9231\n",
      "Epoch 8/50\n",
      "26/26 [==============================] - 0s 308us/sample - loss: 1.4038 - accuracy: 0.9615\n",
      "Epoch 9/50\n",
      "26/26 [==============================] - 0s 154us/sample - loss: 1.3297 - accuracy: 0.9615\n",
      "Epoch 10/50\n",
      "26/26 [==============================] - 0s 115us/sample - loss: 1.2551 - accuracy: 0.9615\n",
      "Epoch 11/50\n",
      "26/26 [==============================] - 0s 116us/sample - loss: 1.1797 - accuracy: 0.9615\n",
      "Epoch 12/50\n",
      "26/26 [==============================] - 0s 116us/sample - loss: 1.1036 - accuracy: 0.9615\n",
      "Epoch 13/50\n",
      "26/26 [==============================] - 0s 116us/sample - loss: 1.0274 - accuracy: 0.9615\n",
      "Epoch 14/50\n",
      "26/26 [==============================] - 0s 231us/sample - loss: 0.9514 - accuracy: 0.9615\n",
      "Epoch 15/50\n",
      "26/26 [==============================] - 0s 154us/sample - loss: 0.8761 - accuracy: 0.9615\n",
      "Epoch 16/50\n",
      "26/26 [==============================] - 0s 116us/sample - loss: 0.8025 - accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "26/26 [==============================] - 0s 115us/sample - loss: 0.7311 - accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "26/26 [==============================] - 0s 115us/sample - loss: 0.6622 - accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "26/26 [==============================] - 0s 116us/sample - loss: 0.5965 - accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "26/26 [==============================] - 0s 231us/sample - loss: 0.5344 - accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "26/26 [==============================] - 0s 154us/sample - loss: 0.4763 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "26/26 [==============================] - 0s 192us/sample - loss: 0.4222 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "26/26 [==============================] - 0s 154us/sample - loss: 0.3723 - accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "26/26 [==============================] - 0s 270us/sample - loss: 0.3265 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "26/26 [==============================] - 0s 193us/sample - loss: 0.2848 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "26/26 [==============================] - 0s 154us/sample - loss: 0.2472 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "26/26 [==============================] - 0s 154us/sample - loss: 0.2134 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "26/26 [==============================] - 0s 154us/sample - loss: 0.1835 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "26/26 [==============================] - 0s 192us/sample - loss: 0.1571 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "26/26 [==============================] - 0s 1ms/sample - loss: 0.1341 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "26/26 [==============================] - 0s 115us/sample - loss: 0.1141 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "26/26 [==============================] - 0s 154us/sample - loss: 0.0969 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "26/26 [==============================] - 0s 154us/sample - loss: 0.0822 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "26/26 [==============================] - 0s 116us/sample - loss: 0.0697 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "26/26 [==============================] - 0s 154us/sample - loss: 0.0591 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "26/26 [==============================] - 0s 115us/sample - loss: 0.0502 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "26/26 [==============================] - 0s 154us/sample - loss: 0.0428 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "26/26 [==============================] - 0s 192us/sample - loss: 0.0365 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "26/26 [==============================] - 0s 116us/sample - loss: 0.0313 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "26/26 [==============================] - 0s 115us/sample - loss: 0.0270 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "26/26 [==============================] - 0s 115us/sample - loss: 0.0234 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "26/26 [==============================] - 0s 115us/sample - loss: 0.0204 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "26/26 [==============================] - 0s 154us/sample - loss: 0.0178 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "26/26 [==============================] - 0s 154us/sample - loss: 0.0157 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "26/26 [==============================] - 0s 154us/sample - loss: 0.0138 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "26/26 [==============================] - 0s 154us/sample - loss: 0.0123 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "26/26 [==============================] - 0s 154us/sample - loss: 0.0110 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "26/26 [==============================] - 0s 116us/sample - loss: 0.0099 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "26/26 [==============================] - 0s 154us/sample - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "26/26 [==============================] - 0s 116us/sample - loss: 0.0081 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(54,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer ='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train,y_train, epochs=50)\n",
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type 'quit' to exit\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You : hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Krithi: Hi there, what can I do for you?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You : quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Krithi: Byeee\n"
     ]
    }
   ],
   "source": [
    "run = True\n",
    "print(\"type 'quit' to exit\")\n",
    "while run:\n",
    "    sentence = input(\"You :\")\n",
    "    if sentence == 'quit':\n",
    "        print(\"Krithi: Byeee\")\n",
    "        break\n",
    "    #sentence = \"tell me a joke\"\n",
    "    sentence = tokenize(sentence)\n",
    "    sentence = [stem(i) for i in sentence if i not in ignore_words]\n",
    "    model_bag = bag_of_words(sentence, all_words)\n",
    "    model_bag = np.array(model_bag)\n",
    "    model_bag = np.reshape(model_bag,(1,54))\n",
    "    pre = model.predict(model_bag)\n",
    "    hi =np.argmax(pre)\n",
    "    for intent in intents['intents']:\n",
    "        if intent['tag'] == tags[hi]:\n",
    "            tag = intent['responses']\n",
    "            j = randint(0,len(tag)-1)\n",
    "            k = \"Krithi: \"+ tag[j]\n",
    "            print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
